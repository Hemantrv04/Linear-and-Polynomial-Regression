{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear and Polynomial Regression Assignment"
      ],
      "metadata": {
        "id": "uh3a4ekHfdX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "Simple Linear Regression models the relationship between two variables by fitting a straight line (Y = mX + c) through the data, where X is the independent variable and Y is the dependent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVi7OxaOfdN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Linearity between X and Y\n",
        "\n",
        "Homoscedasticity (constant variance of errors)\n",
        "\n",
        "Independence of errors\n",
        "\n",
        "Normal distribution of residuals\n",
        "\n",
        "No significant outliers"
      ],
      "metadata": {
        "id": "kjL3RWXrfdEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "\n",
        "Answer:\n",
        "The coefficient\n",
        "ùëö\n",
        "m represents the slope of the line, indicating the change in Y for a one-unit increase in X.\n",
        "\n"
      ],
      "metadata": {
        "id": "RtAM2I5xfc8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept c represent in the equation Y = mX + c?\n",
        "\n",
        "Answer:\n",
        "The intercept\n",
        "ùëê\n",
        "c is the value of Y when X = 0. It represents the point where the line crosses the Y-axis."
      ],
      "metadata": {
        "id": "pjbBvfZmfc1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "Answer:\n",
        "The slope\n",
        "ùëö\n",
        "m is calculated using:\n",
        "\n",
        "ùëö\n",
        "=\n",
        "ùëõ\n",
        "(\n",
        "‚àë\n",
        "ùë•\n",
        "ùë¶\n",
        ")\n",
        "‚àí\n",
        "(\n",
        "‚àë\n",
        "ùë•\n",
        ")\n",
        "(\n",
        "‚àë\n",
        "ùë¶\n",
        ")/\n",
        "ùëõ\n",
        "(\n",
        "‚àë\n",
        "ùë•\n",
        "^2\n",
        ")\n",
        "‚àí\n",
        "(\n",
        "‚àë\n",
        "ùë•\n",
        ")\n",
        "^2\n",
        "\n",
        "\n",
        "where n is the number of data points."
      ],
      "metadata": {
        "id": "bnv0Ry77fcsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "The least squares method minimizes the sum of the squares of the residuals (the differences between observed and predicted values) to find the best-fitting line."
      ],
      "metadata": {
        "id": "h8yQP6m_fckW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "R¬≤ represents the proportion of variance in the dependent variable that is explained by the independent variable.\n",
        "An R¬≤ value closer to 1 indicates a better fit."
      ],
      "metadata": {
        "id": "hVssd9sKfccz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Multiple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables."
      ],
      "metadata": {
        "id": "mLmsJdf_fcVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses two or more independent variables to predict the dependent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "b_zDSWPYfcNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Linearity between predictors and outcome\n",
        "\n",
        "No multicollinearity\n",
        "\n",
        "Homoscedasticity\n",
        "\n",
        "Independence of errors\n",
        "\n",
        "Normal distribution of residuals"
      ],
      "metadata": {
        "id": "h602ZTvYfcEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "Answer:\n",
        "Heteroscedasticity occurs when the variance of residuals is not constant.\n",
        "It affects the reliability of confidence intervals and hypothesis tests, leading to inefficient estimates.\n",
        "\n"
      ],
      "metadata": {
        "id": "LynAbwF7fb9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Remove highly correlated predictors\n",
        "\n",
        "Apply dimensionality reduction (like PCA)\n",
        "\n",
        "Use Ridge Regression (regularization)"
      ],
      "metadata": {
        "id": "uyQxWljtfb0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "Answer:\n",
        "\n",
        "One-hot encoding\n",
        "\n",
        "Label encoding\n",
        "\n",
        "Binary encoding"
      ],
      "metadata": {
        "id": "_aNecoScfbtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "Interaction terms capture the combined effect of two or more variables on the dependent variable, allowing the model to understand complex relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "sp357Iwtfbkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "In Simple Linear Regression, the intercept is the expected value of Y when X = 0.\n",
        "In Multiple Linear Regression, the intercept is the expected value of Y when all predictors are zero, which may not always be meaningful."
      ],
      "metadata": {
        "id": "NPj1SO73fbbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "Answer:\n",
        "The slope indicates the strength and direction of the relationship between a predictor and the dependent variable.\n",
        "A positive slope shows a direct relationship, while a negative slope shows an inverse relationship."
      ],
      "metadata": {
        "id": "5ig9UmqUfbTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "Answer:\n",
        "The intercept provides a baseline value for the dependent variable when all predictors are zero, setting the context for how the variables are related."
      ],
      "metadata": {
        "id": "GSQqqt7SfbKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "Answer:\n",
        "\n",
        "R¬≤ always increases with more predictors, even if they are irrelevant.\n",
        "\n",
        "It does not indicate causality or model correctness.\n",
        "\n",
        "It ignores overfitting risk."
      ],
      "metadata": {
        "id": "GgZI6v7ZfbCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "Answer:\n",
        "A large standard error suggests that the coefficient estimate is unstable and that the predictor may not significantly impact the dependent variable."
      ],
      "metadata": {
        "id": "iuUhBa_lfa5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "Answer:\n",
        "Heteroscedasticity appears as a funnel shape or pattern in residual plots.\n",
        "Addressing it is important because it can lead to inefficient and biased parameter estimates."
      ],
      "metadata": {
        "id": "63Hu_8r4faw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
        "\n",
        "Answer:\n",
        "It suggests that additional predictors are not truly useful and are only inflating the R¬≤ without improving model quality."
      ],
      "metadata": {
        "id": "iZzL8kC1fapw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "Scaling ensures that variables are on the same scale, improving numerical stability and helping in regularization (like Ridge or Lasso Regression)."
      ],
      "metadata": {
        "id": "YaUrnabwfag5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is polynomial regression?\n",
        "\n",
        "Answer:\n",
        "Polynomial Regression models the relationship between independent and dependent variables as an nth degree polynomial."
      ],
      "metadata": {
        "id": "T69TVN-GfaZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "Answer:\n",
        "Linear Regression models straight-line relationships, while Polynomial Regression models curves by including higher-order powers of the predictor variables."
      ],
      "metadata": {
        "id": "TOV1ll_HfaRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "\n",
        "Answer:\n",
        "Polynomial Regression is used when the data shows a non-linear relationship but still needs to be modeled using a linear approach in transformed space."
      ],
      "metadata": {
        "id": "tuJH-2difaIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. What is the general equation for polynomial regression?\n",
        "Answer:\n",
        "\n",
        "ùëå\n",
        "=\n",
        "ùëè\n",
        "0\n",
        "+\n",
        "ùëè\n",
        "1\n",
        "ùëã\n",
        "+\n",
        "ùëè\n",
        "2\n",
        "ùëã\n",
        "2\n",
        "+\n",
        "ùëè\n",
        "3\n",
        "ùëã\n",
        "3\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "ùëè\n",
        "ùëõ\n",
        "ùëã\n",
        "ùëõ\n",
        "\n",
        "where\n",
        "ùëõ\n",
        "n is the degree of the polynomial.\n",
        "\n"
      ],
      "metadata": {
        "id": "kP35NzpvfaAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Answer:\n",
        "Yes, Polynomial Regression can be extended to multiple variables by including cross-product and higher-degree terms for each predictor."
      ],
      "metadata": {
        "id": "cGlPvJsOfZ5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. What are the limitations of polynomial regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Prone to overfitting for high-degree polynomials\n",
        "\n",
        "Extrapolation becomes highly unreliable\n",
        "\n",
        "Sensitive to outliers"
      ],
      "metadata": {
        "id": "I5nS7-JwfZwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Cross-validation\n",
        "\n",
        "Adjusted R¬≤\n",
        "\n",
        "AIC (Akaike Information Criterion)\n",
        "\n",
        "BIC (Bayesian Information Criterion)"
      ],
      "metadata": {
        "id": "lt52uNA_fZnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        "Answer:\n",
        "Visualization helps to detect overfitting, underfitting, and understand the model's behavior across the data range."
      ],
      "metadata": {
        "id": "AtF_oceSfZfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        "Answer:\n",
        "Polynomial Regression can be implemented using PolynomialFeatures from sklearn.preprocessing to create polynomial features and then applying Linear Regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "Oy1ac5ebfYri"
      }
    }
  ]
}